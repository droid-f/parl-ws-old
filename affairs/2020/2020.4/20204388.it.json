{
  "id": 20204388,
  "updated": "2020-12-08T11:12:48Z",
  "additionalIndexing": "34;1236;32;52",
  "affairType": {
    "abbreviation": "Po.",
    "id": 6,
    "name": "Postulato"
  },
  "author": {
    "councillor": {
      "code": 3208,
      "gender": "m",
      "id": 4312,
      "name": "Storni Bruno",
      "officialDenomination": "Storni"
    },
    "faction": {
      "abbreviation": "Gruppo S",
      "id": 2,
      "name": "Gruppo socialista"
    },
    "type": "author"
  },
  "deposit": {
    "council": {
      "abbreviation": "CN",
      "id": 1,
      "name": "Consiglio nazionale",
      "type": "N"
    },
    "date": "2020-12-02T00:00:00Z",
    "legislativePeriod": 51,
    "session": "5107"
  },
  "descriptors": [

  ],
  "drafts": [
    {
      "consultation": {
        "resolutions": [

        ]
      },
      "federalCouncilProposal": {
        "code": "-",
        "date": "2021-02-17T00:00:00Z",
        "text": "Il Consiglio federale propone di respingere il postulato."
      },
      "index": 0,
      "links": [

      ],
      "preConsultations": [

      ],
      "references": [

      ],
      "relatedDepartments": [
        {
          "abbreviation": "DATEC",
          "id": 9,
          "name": "Dipartimento dell'ambiente, dei trasporti, dell'energia e delle comunicazioni",
          "leading": true
        }
      ],
      "states": [
        {
          "date": "/Date(1606863600000+0100)/",
          "id": 24,
          "name": "Non ancora trattato dalla Camera"
        }
      ],
      "texts": [

      ]
    }
  ],
  "language": "it",
  "priorityCouncils": [
    {
      "abbreviation": "CN",
      "id": 1,
      "name": "Consiglio nazionale",
      "type": "N",
      "priority": 1
    }
  ],
  "relatedAffairs": [

  ],
  "roles": [
    {
      "councillor": {
        "code": 3162,
        "gender": "m",
        "id": 4270,
        "name": "Hurni Baptiste",
        "officialDenomination": "Hurni"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3173,
        "gender": "m",
        "id": 4281,
        "name": "Pult Jon",
        "officialDenomination": "Pult"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3175,
        "gender": "f",
        "id": 4283,
        "name": "Roth Franziska",
        "officialDenomination": "Roth Franziska"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2760,
        "gender": "m",
        "id": 4049,
        "name": "Aebischer Matthias",
        "officialDenomination": "Aebischer Matthias"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3120,
        "gender": "f",
        "id": 4219,
        "name": "Crottaz Brigitte",
        "officialDenomination": "Crottaz"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2652,
        "gender": "f",
        "id": 1295,
        "name": "Graf-Litscher Edith",
        "officialDenomination": "Graf-Litscher"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3026,
        "gender": "f",
        "id": 4121,
        "name": "Gysi Barbara",
        "officialDenomination": "Gysi Barbara"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3036,
        "gender": "f",
        "id": 4134,
        "name": "Munz Martina",
        "officialDenomination": "Munz"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2702,
        "gender": "m",
        "id": 3899,
        "name": "Nussbaumer Eric",
        "officialDenomination": "Nussbaumer"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2795,
        "gender": "m",
        "id": 4091,
        "name": "Reynard Mathias",
        "officialDenomination": "Reynard"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3009,
        "gender": "f",
        "id": 4109,
        "name": "Piller Carrard Valérie",
        "officialDenomination": "Piller Carrard"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3094,
        "gender": "f",
        "id": 4199,
        "name": "Seiler Graf Priska",
        "officialDenomination": "Seiler Graf"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3208,
        "gender": "m",
        "id": 4312,
        "name": "Storni Bruno",
        "officialDenomination": "Storni"
      },
      "faction": {
        "abbreviation": "Gruppo S",
        "id": 2,
        "name": "Gruppo socialista"
      },
      "type": "author"
    }
  ],
  "shortId": "20.4388",
  "state": {
    "id": 24,
    "name": "Non ancora trattato dalla Camera",
    "doneKey": "0",
    "newKey": 0
  },
  "texts": [
    {
      "type": {
        "id": 6,
        "name": "Motivazione"
      },
      "value": "<p>Le nuove tecnologie informatiche IA, basate su algoritmi e modelli ML, offrono grandi opportunità in molti campi: medicina, gestione razionale delle risorse, ecc. Esse hanno ormai raggiunto una grande diffusione e stanno diventando capillari e ubiquitari tramite edge computing.</p><p>Modelli ML mirati all'analisi di dati personali per indirizzare pubblicità e comportamenti d'acquisto, riconoscimento vocale, traduzione, solo per citare i più noti, ormai di uso quotidiano.</p><p>Ci sono però altre applicazioni più critiche dove l'AI ha un'interazione fisica diretta con l'ambiente, ad esempio la guida autonoma, che richiedono elevati livelli di sicurezza e di robustezza tecnica.</p><p>I meccanismi di funzionamento e le decisioni dei modelli ML sono basati su multipli livelli di reti neuronali; essi non sono trasparenti, contrariamente agli algoritmi classici basati su regole, che per applicazioni critiche (avionica, medicina, ecc.) sottostanno a certificazione secondo norme di sicurezza definite.</p><p>L'IA non prevede una programmazione imperativa ma organizza un apprendimento autonomo non sempre trasparente.   </p><p>Occorre definire regole e processi affinché anche l'IA possa essere certificata come affidabile ed utilizzabile in ambienti critici per l'incolumità delle persone e la protezione dell'ambiente. Normative adottate ad esempio nel settore degli impianti o degli apparecchi elettrici. </p><p>Altro tema da regolamentare è l'uso dell'IA per applicazioni basate su riconoscimento biometrico, per profiling, identificazione personale e tracciamento personale, cioè tutto quanto ha che fare con la sfera individuale delle persone e diritti fondamentali.</p><p>Da analizzare vi è anche il diritto di informazione alla popolazione quando è confrontata con un' applicazione AI ML(registro algoritmi AI). </p><p>Si chiede di approfondire i lavori IDAG KI 2019, e definire limiti e basi legali per queste applicazioni AI.</p>"
    },
    {
      "type": {
        "id": 14,
        "name": "Risposta del CF / Ufficio"
      },
      "value": "<p>Per il Consiglio federale è importante rispondere in modo adeguato alle sfide dell'intelligenza artificiale (IA). Per questo motivo già nel 2018 ha definito l'IA in quanto tema centrale della Strategia \"Svizzera digitale\" e ha istituito un gruppo di lavoro interdipartimentale sull'IA. Il rapporto di questo gruppo di lavoro del dicembre 2019 fornisce un'ampia panoramica e un'attenta analisi delle condizioni quadro rilevanti in vista di un uso responsabile dell'IA. Evidenzia inoltre le sfide specifiche in diversi campi d'applicazione prendendo in considerazione tutti gli ambiti politici dell'Amministrazione federale. Ne risulta che il quadro giuridico generale in Svizzera è fondamentalmente adeguato e sufficiente per affrontare le sfide dell'IA. Il progetto di revisione della legge sulla protezione dei dati, adottato in occasione della sessione autunnale 2020, apporta dei miglioramenti su diversi punti in questo settore, segnatamente per quanto riguarda le decisioni automatizzate.</p><p>Tuttavia, le necessità d'intervento variano da un settore all'altro. Questo è risaputo e già tenuto in considerazione. Ad esempio, a novembre 2020 il suddetto gruppo di lavoro ha presentato le linee guida per il trattamento dell'IA nell'Amministrazione federale. Queste servono come quadro di orientamento generale e garantiscono una politica coerente per quanto riguarda l'IA. Nell'allegato 2 delle linee guida \"Applicabilità dell'ordinamento giuridico vigente\" viene inoltre evidenziato in modo specifico che l'ordinamento esistente si applica anche all'IA. L'UFCOM, in collaborazione con gli uffici federali interessati, garantisce una valutazione regolare dell'applicazione e dello sviluppo delle linee guida.</p><p>Per l'elaborazione dell'ulteriore necessità d'intervento individuata nel rapporto del gruppo di lavoro succitato, il Consiglio federale ha inoltre attribuito ulteriori mandati d'esame amministrativi interni, in particolare nell'ambito del diritto internazionale e dell'utilizzo dell'IA nella formazione dell'opinione e della volontà pubbliche. Entrambi i rapporti saranno disponibili nel corso del 2021. Infine, nel dicembre 2020 il Consiglio federale ha deciso di valutare entro la metà del 2021 la realizzazione di una rete di competenze in materia di IA nell'Amministrazione federale. Tra l'altro, una tale rete di competenze dovrebbe permettere di attingere ad ampie conoscenze specialistiche.</p><p>Oltre alle suddette attività del gruppo di lavoro, sono già in corso programmi che consentono di analizzare nuovi rischi derivanti dall'IA in collaborazione con gli uffici federali e le imprese. Si tratta ad esempio della Strategia nazionale per la protezione delle infrastrutture critiche 2018-2022 (Strategia PIC) e della Strategia nazionale per la protezione della Svizzera contro i cyber-rischi 2018-2022 (SNPC). Entrambe le strategie prevedono che le analisi dei rischi e della vulnerabilità siano effettuate regolarmente in settori critici come l'approvvigionamento energetico, il sistema sanitario o i trasporti. Nel quadro di queste strategie è possibile rilevare sistematicamente i nuovi rischi basati sull'IA e raccomandare misure per ridurli. Lo stato di attuazione di entrambe le strategie viene comunicato al Consiglio federale a intervalli regolari.</p><p>A questo proposito, il Consiglio federale dispone di diversi canali che gli permettono di seguire l'evoluzione dell'IA e i rischi che ne derivano per la società e l'economia. Se necessario, il Consiglio federale può appoggiarsi su relative analisi per adottare misure volte ad aumentare la sicurezza e l'affidabilità dei sistemi basati sull'IA.</p><p>Il Consiglio federale continuerà a seguire da vicino gli sviluppi nei vari settori di applicazione dell'IA e a intervenire in caso di necessità. Inoltre la Svizzera collabora attivamente con i comitati internazionali al trattamento delle questioni di regolamentazione dell'IA, come ad esempio ai lavori del Consiglio d'Europa al quadro giuridico per l'IA. Tuttavia, in base al rapporto dettagliato del gruppo di lavoro sull'IA del dicembre 2019, ai lavori summenzionati svolti successivamente e ad altri programmi attualmente in corso, il Consiglio federale non vede per ora la necessità di un ulteriore studio.</p>"
    },
    {
      "type": {
        "id": 5,
        "name": "Testo depositato"
      },
      "value": "<p>Il Consiglio federale è incaricato di approfondire in uno studio le necessità di regole per applicazioni di Intelligenza Artificiale basate su algoritmi di machine learning (ML), utilizzati in ambiti tecnologici automatizzati a rischio, in quelli relativi alla sfera personale e dovrà analizzare la necessità di informazione alla popolazione sugli applicativi IA. Lo studio dovrà valutare le necessità di regolamentazione a complemento di quanto sviluppato da IDAG KI (2019).</p>"
    },
    {
      "type": {
        "id": 1,
        "name": "Titolo dell'oggetto"
      },
      "value": "Intelligenza artificiale, regole di sicurezza, trasparenza e informazione nelle applicazioni di machine learning"
    }
  ],
  "title": "Intelligenza artificiale, regole di sicurezza, trasparenza e informazione nelle applicazioni di machine learning"
}