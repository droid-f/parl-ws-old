{
  "id": 20164007,
  "updated": "2019-02-18T19:03:06Z",
  "additionalIndexing": "1236;04;34",
  "affairType": {
    "abbreviation": "Po.",
    "id": 6,
    "name": "Postulato"
  },
  "author": {
    "councillor": {
      "code": 3020,
      "gender": "m",
      "id": 4115,
      "name": "Schwaab Jean Christophe",
      "officialDenomination": "Schwaab"
    },
    "faction": {
      "abbreviation": "Gruppo S",
      "id": 2,
      "name": "Gruppo socialista"
    },
    "type": "author"
  },
  "deposit": {
    "council": {
      "abbreviation": "CN",
      "id": 1,
      "name": "Consiglio nazionale",
      "type": "N"
    },
    "date": "2016-12-14T00:00:00Z",
    "legislativePeriod": 50,
    "session": "5006"
  },
  "descriptors": [

  ],
  "drafts": [
    {
      "consultation": {
        "resolutions": [
          {
            "category": {
              "id": 5,
              "name": "Amm."
            },
            "council": {
              "abbreviation": "CN",
              "id": 1,
              "name": "Consiglio nazionale",
              "type": "N"
            },
            "date": "2018-02-26T00:00:00Z",
            "text": "L'intervento viene ripreso dalla Signora Marti.",
            "type": 90
          },
          {
            "category": {
              "id": 5,
              "name": "Amm."
            },
            "council": {
              "abbreviation": "CN",
              "id": 1,
              "name": "Consiglio nazionale",
              "type": "N"
            },
            "date": "2018-12-14T00:00:00Z",
            "text": "Tolto dal ruolo poiché la trattazione nella Camera non si è conclusa entro due anni",
            "type": 32
          }
        ]
      },
      "federalCouncilProposal": {
        "code": "-",
        "date": "2017-02-15T00:00:00Z",
        "text": "Il Consiglio federale propone di respingere il postulato."
      },
      "index": 0,
      "links": [

      ],
      "preConsultations": [

      ],
      "references": [

      ],
      "relatedDepartments": [
        {
          "abbreviation": "DFF",
          "id": 7,
          "name": "Dipartimento delle Finanze",
          "leading": true
        }
      ],
      "states": [
        {
          "date": "/Date(1481670000000+0100)/",
          "id": 24,
          "name": "Non ancora trattato dalla Camera"
        },
        {
          "date": "/Date(1544742000000+0100)/",
          "id": 27,
          "name": "Liquidato"
        }
      ],
      "texts": [

      ]
    }
  ],
  "handling": {
    "date": "2018-12-14T00:00:00Z",
    "legislativePeriod": 50,
    "session": "5015"
  },
  "language": "it",
  "priorityCouncils": [
    {
      "abbreviation": "CN",
      "id": 1,
      "name": "Consiglio nazionale",
      "type": "N",
      "priority": 1
    }
  ],
  "relatedAffairs": [

  ],
  "roles": [
    {
      "councillor": {
        "code": 2632,
        "gender": "m",
        "id": 1120,
        "name": "Sommaruga Carlo",
        "officialDenomination": "Sommaruga Carlo"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2608,
        "gender": "f",
        "id": 1147,
        "name": "Kiener Nellen Margret",
        "officialDenomination": "Kiener Nellen"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2738,
        "gender": "m",
        "id": 4018,
        "name": "Maire Jacques-André",
        "officialDenomination": "Maire Jacques-André"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2601,
        "gender": "f",
        "id": 1156,
        "name": "Heim Bea",
        "officialDenomination": "Heim"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2792,
        "gender": "m",
        "id": 4076,
        "name": "Hadorn Philipp",
        "officialDenomination": "Hadorn"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2795,
        "gender": "m",
        "id": 4091,
        "name": "Reynard Mathias",
        "officialDenomination": "Reynard"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3007,
        "gender": "m",
        "id": 4113,
        "name": "Tornare Manuel",
        "officialDenomination": "Tornare"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3036,
        "gender": "f",
        "id": 4134,
        "name": "Munz Martina",
        "officialDenomination": "Munz"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3071,
        "gender": "f",
        "id": 4195,
        "name": "Fehlmann Rielle Laurence",
        "officialDenomination": "Fehlmann Rielle"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3084,
        "gender": "f",
        "id": 4197,
        "name": "Marti Min Li",
        "officialDenomination": "Marti Min Li"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3020,
        "gender": "m",
        "id": 4115,
        "name": "Schwaab Jean Christophe",
        "officialDenomination": "Schwaab"
      },
      "faction": {
        "abbreviation": "Gruppo S",
        "id": 2,
        "name": "Gruppo socialista"
      },
      "type": "author"
    },
    {
      "councillor": {
        "code": 3084,
        "gender": "f",
        "id": 4197,
        "name": "Marti Min Li",
        "officialDenomination": "Marti Min Li"
      },
      "type": "assuming"
    }
  ],
  "shortId": "16.4007",
  "state": {
    "id": 27,
    "name": "Liquidato",
    "doneKey": "1",
    "newKey": 0
  },
  "texts": [
    {
      "type": {
        "id": 6,
        "name": "Motivazione"
      },
      "value": "<p>Sempre più spesso enti pubblici e privati prendono decisioni basandosi su algoritmi. Si tratta, ad esempio, di decisioni automatizzate che riguardano la concessione o il rifiuto di una prestazione, la selezione o l'ammissione, la conclusione di un contratto e la definizione delle relative condizioni. Queste decisioni non si basano sul potere discrezionale di una persona e rischiano pertanto di essere arbitrarie e di violare direttamente alcuni diritti fondamentali (ad es. nel caso in cui un veicolo autonomo deve scegliere se uccidere il suo conducente o investire un pedone o quando un algoritmo crea una discriminazione razziale sulla base di criteri che, di per sé, non sono discriminatori). Va ricordato che lo Stato è legato ai diritti fondamentali e deve provvedere affinché questi siano rispettati anche nelle relazioni tra privati (art. 35 Cost.).</p><p>Esiste inoltre il rischio che nessuno voglia assumersi la responsabilità di decisioni prese in modo automatizzato e che nessuno conosca le ragioni di tali decisioni. La comunità scientifica inizia a sviluppare le condizioni necessarie per l'utilizzo di algoritmi che rispettino i diritti fondamentali: responsabilità (per qualsiasi sistema algoritmico dev'esserci una persona in grado di far fronte agli effetti indesiderati), spiegabilità (qualsiasi decisione prodotta da un algoritmo dovrebbe essere spiegata alle persone interessate), esattezza (le fonti di errori devono essere identificate, registrate e confrontate), controllabilità (gli algoritmi devono essere sviluppati per permettere a terzi di rilevarne e rivederne il comportamento), giustiziabilità (per evitare le distorsioni di decisioni automatizzate, gli algoritmi che producono decisioni riguardanti individui devono essere valutati per misurare eventuali effetti discriminatori; i risultati e i criteri di queste valutazioni devono essere spiegati e pubblicati; cfr. ad es. Diakopoulos/Friedler in Technology Review 2016). È opportuno esaminare in quale misura le basi legali, soprattutto quelle costituzionali, permettono di applicare questi principi agli algoritmi o se sono necessari complementi.</p>"
    },
    {
      "type": {
        "id": 14,
        "name": "Risposta del CF / Ufficio"
      },
      "value": "<p>Il Consiglio federale condivide l'opinione espressa dall'autore del postulato secondo cui gli algoritmi sono un elemento chiave del processo di digitalizzazione di tutti i servizi. Per approfittare in modo duraturo delle opportunità offerte da questa evoluzione è necessario esaminare i rischi potenziali legati agli algoritmi che possono mettere a repentaglio i diritti costituzionali. Ciò riguarda sia gli algoritmi programmati dalla mente umana sia quelli sviluppati dall'intelligenza artificiale.</p><p>Tuttavia, gli algoritmi rappresentano solo una delle componenti del processo dell'elaborazione dei dati. La struttura del processo comprende, dalla fase iniziale a quella finale, dati concreti che possono ripercuotersi negativamente sulle persone interessate o sugli utenti. Pertanto gli algoritmi non dovrebbero essere considerati isolatamente, bensì esaminati nel contesto più generale del trattamento dei dati. Questo perché anche gli algoritmi che funzionano su una base neutra possono produrre, a causa di dati specifici, risultati che violano i diritti fondamentali. Al fine di tenere conto di questa eventualità e del contesto nella sua interezza, il Consiglio federale ha intrapreso diverse misure:</p><p>- Il gruppo di esperti istituito in attuazione della mozione Rechsteiner Paul 13.3841, \"Commissione di esperti per il futuro del trattamento e della sicurezza dei dati\", tratta la questione degli algoritmi sotto vari punti di vista. Il gruppo di esperti si occupa di temi specifici come il futuro della protezione della personalità, la tutela dei consumatori, algoritmi e questioni etiche. Esso affronta anche il seguente interrogativo di fondo: in che misura e dove l'analisi dei rischi e la preparazione di misure riguardanti gli algoritmi possono generare un valore aggiunto? Il rapporto del gruppo di esperti con le relative raccomandazioni è atteso a metà del 2018.</p><p>- Sul piano legislativo, la revisione in corso della legge sulla protezione dei dati contempla diverse situazioni nelle quali il trattamento dei dati personali si svolge attraverso algoritmi. Pertanto viene introdotto l'obbligo di informare e sentire la persona interessata qualora la decisione presa nei suoi confronti, basata esclusivamente su un sistema automatizzato per il trattamento dei dati, abbia per lei conseguenze giuridiche o ripercussioni considerevoli. Inoltre, il diritto di essere informata consente alla persona interessata di chiedere ulteriori informazioni sulla decisione presa nonché su modalità e conseguenze di quest'ultima. Il progetto prevede inoltre delle misure concernenti la profilazione, basata spesso su algoritmi. Infine, i responsabili saranno tenuti a effettuare una valutazione d'impatto relativa alla protezione dei dati nei casi in cui si presume che il trattamento dei dati possa ledere la personalità o i diritti fondamentali della persona interessata. In questo contesto occorre anche esaminare delle misure volte alla protezione della persona interessata.</p><p>Le misure elencate dimostrano che il tema \"algoritmi e diritti costituzionali\" è riconosciuto e già inserito nelle attività in corso. Il Consiglio federale ritiene che proseguire e consolidare tali attività sia il modo più efficace per garantire che gli algoritmi siano applicati nel rispetto dei diritti fondamentali.</p>"
    },
    {
      "type": {
        "id": 5,
        "name": "Testo depositato"
      },
      "value": "<p>Il Consiglio federale analizza l'impatto dell'utilizzo di algoritmi da parte di enti pubblici e privati sui diritti costituzionali. All'occorrenza presenterà le misure necessarie per rendere l'utilizzo di algoritmi trasparente, responsabile e rispettoso dei diritti fondamentali.</p>"
    },
    {
      "type": {
        "id": 1,
        "name": "Titolo dell'oggetto"
      },
      "value": "Per algoritmi che rispettino i diritti fondamentali"
    }
  ],
  "title": "Per algoritmi che rispettino i diritti fondamentali"
}