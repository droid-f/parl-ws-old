{
  "id": 20163914,
  "updated": "2019-02-18T19:03:06Z",
  "additionalIndexing": "34",
  "affairType": {
    "abbreviation": "Po.",
    "id": 6,
    "name": "Postulat"
  },
  "author": {
    "councillor": {
      "code": 3060,
      "gender": "m",
      "id": 4182,
      "name": "Béglé Claude",
      "officialDenomination": "Béglé"
    },
    "faction": {
      "abbreviation": "Fraktion C",
      "code": "C",
      "id": 3,
      "name": "CVP-Fraktion"
    },
    "type": "author"
  },
  "deposit": {
    "council": {
      "abbreviation": "NR",
      "id": 1,
      "name": "Nationalrat",
      "type": "N"
    },
    "date": "2016-11-28T00:00:00Z",
    "legislativePeriod": 50,
    "session": "5006"
  },
  "descriptors": [

  ],
  "drafts": [
    {
      "consultation": {
        "resolutions": [
          {
            "category": {
              "id": 3,
              "name": "Normal"
            },
            "council": {
              "abbreviation": "NR",
              "id": 1,
              "name": "Nationalrat",
              "type": "N"
            },
            "date": "2018-02-28T00:00:00Z",
            "text": "Ablehnung",
            "type": 22
          }
        ]
      },
      "federalCouncilProposal": {
        "code": "-",
        "date": "2017-01-25T00:00:00Z",
        "text": "Der Bundesrat beantragt die Ablehnung des Postulates."
      },
      "index": 0,
      "links": [

      ],
      "preConsultations": [

      ],
      "references": [

      ],
      "relatedDepartments": [
        {
          "abbreviation": "EFD",
          "id": 7,
          "name": "Finanzdepartement",
          "leading": true
        }
      ],
      "states": [
        {
          "date": "/Date(1480287600000+0100)/",
          "id": 24,
          "name": "Im Rat noch nicht behandelt"
        },
        {
          "date": "/Date(1519772400000+0100)/",
          "id": 27,
          "name": "Erledigt"
        }
      ],
      "texts": [

      ]
    }
  ],
  "handling": {
    "date": "2018-02-28T00:00:00Z",
    "legislativePeriod": 50,
    "session": "5012"
  },
  "language": "de",
  "priorityCouncils": [
    {
      "abbreviation": "NR",
      "id": 1,
      "name": "Nationalrat",
      "type": "N",
      "priority": 1
    }
  ],
  "relatedAffairs": [

  ],
  "roles": [
    {
      "councillor": {
        "code": 3060,
        "gender": "m",
        "id": 4182,
        "name": "Béglé Claude",
        "officialDenomination": "Béglé"
      },
      "faction": {
        "abbreviation": "Fraktion C",
        "code": "C",
        "id": 3,
        "name": "CVP-Fraktion"
      },
      "type": "author"
    }
  ],
  "shortId": "16.3914",
  "state": {
    "id": 27,
    "name": "Erledigt",
    "doneKey": "1",
    "newKey": 0
  },
  "texts": [
    {
      "type": {
        "id": 6,
        "name": "Begründung"
      },
      "value": "<p>Dank Algorithmen erhalten wir bei unseren Internetrecherchen Treffer. Ein Algorithmus ist eine Folge von Anweisungen, mit denen die Informationen, die von Milliarden von Menschen konsumiert werden, hierarchisiert werden. Die zentrale Frage ist: Welche Information erscheint zuerst auf unserem Bildschirm? Die Reihenfolge widerspiegelt ein Wertesystem, ja sogar eine Weltanschauung.</p><p>Heutzutage entscheiden private Firmen darüber. Die Informationen können nach vier Kriterien hierarchisiert werden: Beliebtheit (Anzahl Aufrufe), Autorität (Verweise/Hyperlinks), Reputation (Anzahl Retweets/Likes), vorausgesagtes Verhalten anhand der im Internet hinterlassenen Spuren. Diese Hierarchisierung birgt jedoch Risiken.</p><p>1. Algorithmen beeinträchtigen tendenziell den Grundsatz der Freiheit.</p><p>Um die Internetnutzerinnen und -nutzer zu binden, zeigen sie zuerst die meistaufgerufenen Informationen an und jene, die der Nutzermeinung entsprechen, während der Rest beiseitegelassen wird. Dadurch entstehen sogenannte Filterblasen. Die Bedrohung für die Demokratie ist deshalb umso grösser, als zunehmend viele Bürgerinnen und Bürger Qualitätsmedien verschmähen und sich stattdessen in den sozialen Netzwerken informieren.</p><p>2. Algorithmen verschärfen die Ungleichheiten.</p><p>Algorithmen globalisieren den Meinungsmarkt und geben den \"Besten\" übermässige Sichtbarkeit. Der Rest, insbesondere der \"Durchschnitt\", wird dabei gerne vergessen: 95 Prozent der Internetnutzerinnen und -nutzer konsumieren 0,03 Prozent der Inhalte (laut dem Soziologen Dominique Cardon).</p><p>3. Dies kann zu Diskriminierung führen.</p><p>Das Dynamic Pricing beruht auf Algorithmen und kann treue, eilige oder abhängige Kunden benachteiligen, indem es ihnen höhere Preise anbietet, und den Kunden \"ohne Potenzial\" attraktive Angebote vorenthalten.</p><p>Mit grösserer Transparenz und klarerer Festlegung der Verantwortlichkeiten könnte die politische, wirtschaftliche und soziale Macht der Algorithmen begrenzt werden.</p>"
    },
    {
      "type": {
        "id": 14,
        "name": "Antwort BR / Büro"
      },
      "value": "<p>Such-, Begegnungs-, Medien-, Bewertungs- und Marktplatzplattformen im Netz sind zu einem nicht mehr wegzudenkenden Bestandteil der modernen Lebenswelt geworden. Sie verändern das Leben jedes Einzelnen und werden zunehmend die Grundwerte der Gesellschaft prägen. Grundlage für diese Systeme und Plattformen sind Algorithmen, welche die dafür notwendige Datenbearbeitung ermöglichen. Angesichts dieser Entwicklung teilt der Bundesrat die Einschätzung des Postulates, dass den möglichen Risiken durch Algorithmen nachgegangen werden muss, wenn die Chancen nachhaltig genutzt werden sollen. Allerdings dürfen Algorithmen nicht isoliert, sondern müssen ganzheitlich im Kontext der Datenbearbeitung und der beabsichtigten Funktionalität der Systeme und Plattformen betrachtet werden. Vor diesem Hintergrund hat der Bundesrat verschiedene Massnahmen ergriffen.</p><p>- Die in Umsetzung der Motion Rechsteiner Paul 13.3841, \"Expertenkommission zur Zukunft der Datenbearbeitung und Datensicherheit\", eingesetzte Expertengruppe geht dem Thema der Algorithmen unter verschiedenen Gesichtspunkten nach. Neben spezifischen Themen - etwa digitale Manipulation (Big Nudging, Filter Bubble usw.) - verfolgt sie übergreifende Themenkomplexe. Zu diesen gehören die Fragen, inwiefern ethische Grundsätze im Zusammenspiel mit rechtlichen Auflagen den Missbrauch in der Datenbearbeitung im Allgemeinen und bei den Algorithmen im Besonderen verhindern könnten und welche ethischen Grundsätze dies sein könnten. Der Bericht der Expertengruppe mit entsprechenden Empfehlungen wird Mitte 2018 erwartet.</p><p>- Im Bereich der Personendaten berücksichtigt die laufende Revision des Datenschutzgesetzes verschiedene Konstellationen, in denen die Bearbeitung von Personendaten durch Algorithmen erfolgt. So wird eine Informations- und Anhörungspflicht der betroffenen Person eingeführt, wenn ihr gegenüber eine Entscheidung gefällt wird, die ausschliesslich auf einer automatisierten Datenbearbeitung beruht und rechtliche Wirkungen oder erhebliche Auswirkungen auf die betroffene Person hat. Mit dem Auskunftsrecht soll die betroffene Person darüber hinaus weitere Informationen über das Ergebnis, das Zustandekommen und die Auswirkungen der Entscheidung einfordern können. Die Vorlage enthält auch Massnahmen zum Profiling, das häufig auf der Verwendung von Algorithmen beruht. Schliesslich sollen die Verantwortlichen verpflichtet werden, eine Datenschutz-Folgenabschätzung zu erstellen, wenn die Bearbeitung zu einer Verletzung der Persönlichkeit der betroffenen Person oder der Grundrechte führen könnte. In diesem Rahmen müssen auch Massnahmen zum Schutz der betroffenen Person geprüft werden.</p><p>- Forschung und Bildung: Der Bundesrat hat 2015 das nationale Forschungsprogramm zu Big Data (NFP 75) lanciert. Ende letzten Jahres wurden im Rahmen von Modul 2 (gesellschaftliche, regulatorische und bildungsbezogene Massnahmen) verschiedene Projekte genehmigt, die sich mit ethischen Fragen im Bereich der Datenbearbeitung und Big Data beschäftigen.</p><p>Die aufgelisteten Massnahmen zeigen, dass das Thema \"Algorithmen und Ethik im Netz\" bereits in die laufenden Aktivitäten integriert ist. Dem Bundesrat erscheint eine Weiterführung und Stärkung dieser Aktivitäten der effektivste Weg, um das Thema anzugehen.</p>"
    },
    {
      "type": {
        "id": 5,
        "name": "Eingereichter Text"
      },
      "value": "<p>Der Bundesrat wird beauftragt zu prüfen, was von Algorithmen im In- und Ausland aus ethischer Sicht erwartet oder verlangt werden kann. Algorithmen sind intransparent, ihre Verantwortlichkeit ist unscharf, ihre Pflichten sind beschränkt. Wie funktionieren Algorithmen? An wen kann man sich bei Fehlinformationen wenden? Unterstehen Algorithmen schweizerischem Recht? Der ständig wachsende Einfluss der Algorithmen muss gesteuert werden, ohne dass dabei ihr Nutzen geschmälert wird.</p>"
    },
    {
      "type": {
        "id": 1,
        "name": "Titel des Geschäftes"
      },
      "value": "Wie bringt man Ethik in die Algorithmen?"
    }
  ],
  "title": "Wie bringt man Ethik in die Algorithmen?"
}