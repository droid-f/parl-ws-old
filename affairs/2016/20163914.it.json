{
  "id": 20163914,
  "updated": "2019-02-18T19:03:06Z",
  "additionalIndexing": "34",
  "affairType": {
    "abbreviation": "Po.",
    "id": 6,
    "name": "Postulato"
  },
  "author": {
    "councillor": {
      "code": 3060,
      "gender": "m",
      "id": 4182,
      "name": "Béglé Claude",
      "officialDenomination": "Béglé"
    },
    "faction": {
      "abbreviation": "Gruppo C",
      "id": 3,
      "name": "Gruppo PPD"
    },
    "type": "author"
  },
  "deposit": {
    "council": {
      "abbreviation": "CN",
      "id": 1,
      "name": "Consiglio nazionale",
      "type": "N"
    },
    "date": "2016-11-28T00:00:00Z",
    "legislativePeriod": 50,
    "session": "5006"
  },
  "descriptors": [

  ],
  "drafts": [
    {
      "consultation": {
        "resolutions": [
          {
            "category": {
              "id": 3,
              "name": "Normale"
            },
            "council": {
              "abbreviation": "CN",
              "id": 1,
              "name": "Consiglio nazionale",
              "type": "N"
            },
            "date": "2018-02-28T00:00:00Z",
            "text": "Reiezione",
            "type": 22
          }
        ]
      },
      "federalCouncilProposal": {
        "code": "-",
        "date": "2017-01-25T00:00:00Z",
        "text": "Il Consiglio federale propone di respingere il postulato."
      },
      "index": 0,
      "links": [

      ],
      "preConsultations": [

      ],
      "references": [

      ],
      "relatedDepartments": [
        {
          "abbreviation": "DFF",
          "id": 7,
          "name": "Dipartimento delle Finanze",
          "leading": true
        }
      ],
      "states": [
        {
          "date": "/Date(1480287600000+0100)/",
          "id": 24,
          "name": "Non ancora trattato dalla Camera"
        },
        {
          "date": "/Date(1519772400000+0100)/",
          "id": 27,
          "name": "Liquidato"
        }
      ],
      "texts": [

      ]
    }
  ],
  "handling": {
    "date": "2018-02-28T00:00:00Z",
    "legislativePeriod": 50,
    "session": "5012"
  },
  "language": "it",
  "priorityCouncils": [
    {
      "abbreviation": "CN",
      "id": 1,
      "name": "Consiglio nazionale",
      "type": "N",
      "priority": 1
    }
  ],
  "relatedAffairs": [

  ],
  "roles": [
    {
      "councillor": {
        "code": 3060,
        "gender": "m",
        "id": 4182,
        "name": "Béglé Claude",
        "officialDenomination": "Béglé"
      },
      "faction": {
        "abbreviation": "Gruppo C",
        "id": 3,
        "name": "Gruppo PPD"
      },
      "type": "author"
    }
  ],
  "shortId": "16.3914",
  "state": {
    "id": 27,
    "name": "Liquidato",
    "doneKey": "1",
    "newKey": 0
  },
  "texts": [
    {
      "type": {
        "id": 6,
        "name": "Motivazione"
      },
      "value": "<p>Grazie agli algoritmi, facendo le nostre ricerche su Internet otteniamo risultati. Gli algoritmi sono un insieme di istruzioni che permettono di gerarchizzare le informazioni utilizzate da miliardi di utenti. La domanda di fondo è: qual è l'informazione che arriverà per prima sullo schermo? Questa gerarchizzazione riflette un sistema di valori, una visione del mondo.</p><p>Oggi questa decisione è in mano a società private. Le informazioni possono essere gerarchizzate in base a quattro criteri: la notorietà di un sito (il numero di visitatori), l'autorialità (i rinvii e i collegamenti ipertestuali), la reputazione online (il numero di retweet e like) e le previsioni sul comportamento degli utenti basate sulle tracce lasciate in rete. Questa gerarchizzazione comporta però alcuni rischi.</p><p>1. Gli algoritmi tendono a limitare il principio della libertà.</p><p>Per fidelizzare gli internauti, gli algoritmi prediligono le informazioni più cliccate e quelle più vicine alle loro opinioni, tralasciando le altre. Questo modo di estrapolare le informazioni crea una \"bolla dei filtri\". La minaccia per la democrazia è ancora più seria se si considera che una parte sempre maggiore di cittadini trascura i media di qualità e utilizza soltanto le reti sociali.</p><p>2. Gli algoritmi tendono ad accentuare le disuguaglianze.</p><p>Globalizzando i mercati di opinione gli algoritmi danno ai \"migliori\" una visibilità eccessiva. Il resto, segnatamente la \"media\", corre il rischio di essere dimenticata. Secondo il sociologo Dominique Cardon, il 95 per cento degli internauti si concentra sullo 0,03 per cento dei contenuti.</p><p>3. Questa situazione può comportare discriminazioni.</p><p>Basandosi sugli algoritmi, il pricing dinamico può penalizzare i clienti fedeli, impazienti o dipendenti imponendo loro prezzi più elevati ed escludere dalle migliori offerte i clienti \"senza potenziale\".</p><p>Una maggiore trasparenza e una definizione più chiara delle responsabilità potrebbero contenere il potere politico, economico e sociale degli algoritmi.</p>"
    },
    {
      "type": {
        "id": 14,
        "name": "Risposta del CF / Ufficio"
      },
      "value": "<p>Consultare piattaforme digitali (motori di ricerca, reti sociali, informazione, servizi di confronto e mercati virtuali) è diventata un'attività essenziale del nostro modo di vivere. Queste piattaforme hanno modificato la nostra quotidianità e caratterizzano sempre più i valori fondamentali della società. Il funzionamento delle piattaforme e dei sistemi si basa su algoritmi che permettono di elaborare i dati necessari. Alla luce di questa evoluzione il Consiglio federale condivide l'opinione espressa dall'autore del postulato, secondo il quale è necessario esaminare i rischi potenziali legati agli algoritmi per approfittare in modo duraturo delle opportunità che offrono. Tuttavia, gli algoritmi non dovrebbero essere considerati isolatamente, bensì esaminati nel contesto più generale dell'elaborazione dei dati e delle funzionalità previste dei sistemi e delle piattaforme. Per questo motivo il Consiglio federale ha deciso di adottare diverse misure.</p><p>- Il gruppo di esperti istituito in attuazione della mozione Rechsteiner Paul 13.3841, \"Commissione di esperti per il futuro del trattamento e della sicurezza dei dati\", tratta la questione degli algoritmi sotto vari punti di vista. Oltre a temi specifici come la manipolazione digitale (\"big nudging\", bolla dei filtri, ecc.), il gruppo di esperti affronta tematiche trasversali, fra le quali il seguente interrogativo: in che misura i principi etici, insieme alle condizioni legali, potrebbero impedire abusi nel trattamento dei dati in generale e nel meccanismo degli algoritmi in particolare? Quali principi etici potrebbero essere presi in considerazione? Il rapporto e le raccomandazioni del gruppo di esperti è atteso a metà del 2018.</p><p>- Per quanto riguarda i dati personali, la revisione in corso della legge sulla protezione dei dati tiene conto di diverse situazioni in cui il trattamento dei dati personali si svolge attraverso algoritmi. Pertanto viene introdotto l'obbligo di informare e di sentire la persona interessata qualora la decisione presa nei suoi confronti, basata esclusivamente su un sistema automatizzato per il trattamento dei dati, abbia per lei conseguenze giuridiche o ripercussioni considerevoli. Inoltre, il diritto di essere informata consente alla persona interessata di chiedere ulteriori informazioni sulla decisione presa nonché su modalità e conseguenze di quest'ultima. Il progetto prevede inoltre delle misure concernenti la profilazione, basata spesso su algoritmi. Infine, i responsabili saranno tenuti a effettuare una valutazione d'impatto relativa alla protezione dei dati nei casi in cui si presume che il trattamento dei dati possa ledere la personalità o i diritti fondamentali della persona interessata. In questo contesto occorre anche esaminare delle misure volte alla protezione della persona interessata.</p><p>- Ricerca e formazione: nel 2015 il Consiglio federale ha lanciato il Programma nazionale di ricerca \"Big Data\" (PNR 75). A fine 2016, nel quadro del secondo modulo (sfide sociali e regolatorie, questioni inerenti alla formazione) sono stati approvati diversi progetti che trattano questioni etiche nell'ambito del trattamento dei dati e della problematica dei big data.</p><p>Le misure elencate dimostrano che il tema degli algoritmi e dell'etica in rete è già inserito nelle attività in corso. Il Consiglio federale ritiene che il modo più efficace di affrontarlo sia di proseguire e consolidare tali attività.</p>"
    },
    {
      "type": {
        "id": 5,
        "name": "Testo depositato"
      },
      "value": "<p>Il Consiglio federale è incaricato di esaminare cosa ci si può aspettare e/o esigere, dal punto di vista etico, dagli algoritmi in Svizzera e all'estero. Infatti gli algoritmi non sono trasparenti, la loro responsabilità è opaca, i loro obblighi legali sono limitati. Come funzionano gli algoritmi? A chi ci si può rivolgere in caso di informazioni errate? Soggiacciono alla legge svizzera? È necessario canalizzare l'influenza crescente degli algoritmi senza disperdere i benefici prodotti.</p>"
    },
    {
      "type": {
        "id": 1,
        "name": "Titolo dell'oggetto"
      },
      "value": "Come introdurre un'etica dell'algoritmo?"
    }
  ],
  "title": "Come introdurre un'etica dell'algoritmo?"
}