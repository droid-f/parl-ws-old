{
  "id": 20164007,
  "updated": "2019-02-18T19:03:06Z",
  "additionalIndexing": "1236;04;34",
  "affairType": {
    "abbreviation": "Po.",
    "id": 6,
    "name": "Postulat"
  },
  "author": {
    "councillor": {
      "code": 3020,
      "gender": "m",
      "id": 4115,
      "name": "Schwaab Jean Christophe",
      "officialDenomination": "Schwaab"
    },
    "faction": {
      "abbreviation": "Groupe S",
      "id": 2,
      "name": "Groupe socialiste"
    },
    "type": "author"
  },
  "deposit": {
    "council": {
      "abbreviation": "CN",
      "id": 1,
      "name": "Conseil national",
      "type": "N"
    },
    "date": "2016-12-14T00:00:00Z",
    "legislativePeriod": 50,
    "session": "5006"
  },
  "descriptors": [

  ],
  "drafts": [
    {
      "consultation": {
        "resolutions": [
          {
            "category": {
              "id": 5,
              "name": "Adm"
            },
            "council": {
              "abbreviation": "CN",
              "id": 1,
              "name": "Conseil national",
              "type": "N"
            },
            "date": "2018-02-26T00:00:00Z",
            "text": "L'intervention est reprise par Madame Marti.",
            "type": 90
          },
          {
            "category": {
              "id": 5,
              "name": "Adm"
            },
            "council": {
              "abbreviation": "CN",
              "id": 1,
              "name": "Conseil national",
              "type": "N"
            },
            "date": "2018-12-14T00:00:00Z",
            "text": "Classé car le conseil n’a pas achevé son examen dans un délai de deux ans",
            "type": 32
          }
        ]
      },
      "federalCouncilProposal": {
        "code": "-",
        "date": "2017-02-15T00:00:00Z",
        "text": "Le Conseil fédéral propose de rejeter le postulat."
      },
      "index": 0,
      "links": [

      ],
      "preConsultations": [

      ],
      "references": [

      ],
      "relatedDepartments": [
        {
          "abbreviation": "DFF",
          "id": 7,
          "name": "Département des finances",
          "leading": true
        }
      ],
      "states": [
        {
          "date": "/Date(1481670000000+0100)/",
          "id": 24,
          "name": "Non encore traité au conseil"
        },
        {
          "date": "/Date(1544742000000+0100)/",
          "id": 27,
          "name": "Liquidé"
        }
      ],
      "texts": [

      ]
    }
  ],
  "handling": {
    "date": "2018-12-14T00:00:00Z",
    "legislativePeriod": 50,
    "session": "5015"
  },
  "language": "fr",
  "priorityCouncils": [
    {
      "abbreviation": "CN",
      "id": 1,
      "name": "Conseil national",
      "type": "N",
      "priority": 1
    }
  ],
  "relatedAffairs": [

  ],
  "roles": [
    {
      "councillor": {
        "code": 2632,
        "gender": "m",
        "id": 1120,
        "name": "Sommaruga Carlo",
        "officialDenomination": "Sommaruga Carlo"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2608,
        "gender": "f",
        "id": 1147,
        "name": "Kiener Nellen Margret",
        "officialDenomination": "Kiener Nellen"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2738,
        "gender": "m",
        "id": 4018,
        "name": "Maire Jacques-André",
        "officialDenomination": "Maire Jacques-André"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2601,
        "gender": "f",
        "id": 1156,
        "name": "Heim Bea",
        "officialDenomination": "Heim"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2792,
        "gender": "m",
        "id": 4076,
        "name": "Hadorn Philipp",
        "officialDenomination": "Hadorn"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2795,
        "gender": "m",
        "id": 4091,
        "name": "Reynard Mathias",
        "officialDenomination": "Reynard"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3007,
        "gender": "m",
        "id": 4113,
        "name": "Tornare Manuel",
        "officialDenomination": "Tornare"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3036,
        "gender": "f",
        "id": 4134,
        "name": "Munz Martina",
        "officialDenomination": "Munz"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3071,
        "gender": "f",
        "id": 4195,
        "name": "Fehlmann Rielle Laurence",
        "officialDenomination": "Fehlmann Rielle"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3084,
        "gender": "f",
        "id": 4197,
        "name": "Marti Min Li",
        "officialDenomination": "Marti Min Li"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3020,
        "gender": "m",
        "id": 4115,
        "name": "Schwaab Jean Christophe",
        "officialDenomination": "Schwaab"
      },
      "faction": {
        "abbreviation": "Groupe S",
        "id": 2,
        "name": "Groupe socialiste"
      },
      "type": "author"
    },
    {
      "councillor": {
        "code": 3084,
        "gender": "f",
        "id": 4197,
        "name": "Marti Min Li",
        "officialDenomination": "Marti Min Li"
      },
      "type": "assuming"
    }
  ],
  "shortId": "16.4007",
  "state": {
    "id": 27,
    "name": "Liquidé",
    "doneKey": "1",
    "newKey": 0
  },
  "texts": [
    {
      "type": {
        "id": 6,
        "name": "Développement"
      },
      "value": "<p>De plus en plus de décisions étatiques, mais aussi privées, seront prises à l'aide d'algorithmes. Il pourra s'agir par exemple de décisions automatisées d'octroi ou de refus de prestation, de sélection ou d'admission, de conclusion d'un contrat et de la fixation de ses conditions. Ces décisions qui ne sont pas fondées sur le pouvoir d'appréciation d'un humain risquent d'être entachées d'arbitraire mais aussi de toucher directement certains droits fondamentaux (par ex. lorsqu'un véhicule autonome est confronté au dilemme de tuer son conducteur ou d'écraser un piéton; ou lorsqu'un algorithme crée une discrimination raciale sur la base de critères en soi non discriminants). Or, l'Etat est lié aux droits fondamentaux, et il doit veiller à ce que les privés les respectent dans leurs relations (art. 35 Cst.).</p><p>Le risque existe en outre que plus personne n'endosse la responsabilité des décisions prises de manière automatisée et que plus personne n'en connaisse les raisons. La communauté scientifique commence donc à développer les conditions nécessaires à l'usage d'algorithmes respectueux des droits fondamentaux: responsabilité (pour tout système algorithmique, il doit y avoir une personne ayant le pouvoir de faire face à ses effets indésirables), explicabilité (toute décision produite par un algorithme devrait être expliquée aux personnes concernées), exactitude (les sources d'erreur doivent être identifiées, consignées et comparées), auditabilité (les algorithmes doivent être développés pour permettre à des tiers d'en sonder et d'en revoir le comportement) et justiciabilité (pour éviter les biais des décisions automatisées, les algorithmes qui prennent des décisions au sujet des individus doivent être évalués pour que leurs effets discriminatoires puissent être mesurés). Les résultats et critères de ces évaluations devant être expliqués et publiés (cf. par ex. Diakopoulos/Friedler in Technology Review 2016). Il convient d'examiner dans quelles mesures les bases légales, voire constitutionnelles, existantes permettent d'appliquer ces principes aux algorithmes ou si des compléments sont nécessaires.</p>"
    },
    {
      "type": {
        "id": 14,
        "name": "Réponse CF / Bureau"
      },
      "value": "<p>Le Conseil fédéral partage l'avis de l'auteur du postulat sur le fait que les algorithmes jouent un rôle fondamental dans le processus de numérisation de toutes les prestations de services. Afin de tirer durablement parti des chances qu'offre cette évolution, il importe d'examiner les risques liés au mécanisme des algorithmes et susceptibles de menacer les droits ancrés dans la Constitution. Il conviendra ainsi d'examiner les risques liés aussi bien aux algorithmes programmés qu'aux algorithmes issus de l'intelligence artificielle.</p><p>Les algorithmes ne sont toutefois que l'une des composantes du processus de traitement des données. Celui-ci comprend, dans ses phases initiale et finale, des données concrètes pouvant éventuellement susciter des effets négatifs pour les personnes concernées ou pour les utilisateurs. C'est pourquoi il importe de ne pas considérer les algorithmes isolément, mais de les examiner dans leur contexte général qui est celui du processus de traitement des données. Car même des algorithmes fonctionnant sur une base neutre peuvent, en raison de données spécifiques, produire des résultats susceptibles d'engendrer une violation des droits fondamentaux. Afin de tenir compte de cette éventualité et eu égard au contexte général, le Conseil fédéral a arrêté diverses mesures:</p><p>- Instituée dans le cadre de la mise en oeuvre de la motion Rechsteiner Paul 13.3841, \"Commission d'experts pour l'avenir du traitement et de la sécurité des données\", étudie la question des algorithmes sous différents points de vue. Elle se penchera, d'une part, sur des thèmes spécifiques tels que l'avenir de la protection de la personnalité, la protection des consommateurs, les algorithmes et les problèmes d'éthique et, d'autre part, sur la question fondamentale consistant à déterminer dans quelle mesure une analyse des risques et la mise en place de mesures touchant le fonctionnement des algorithmes est susceptible d'apporter une plus-value et, le cas échéant, dans quels domaines. La commission d'experts devrait présenter son rapport et ses recommandations en la matière au milieu de l'année 2018.</p><p>- Au niveau législatif, la révision en cours de la loi sur la protection des données tient compte des différentes situations dans lesquelles le traitement de données personnelles s'effectue par le biais d'algorithmes. Une obligation d'informer et d'auditionner la personne concernée devra ainsi être observée lorsqu'une décision est prise sur la base exclusive d'un système automatisé de traitement de données et que des conséquences juridiques ou des répercussions importantes sont attendues. Grâce au droit d'être informé qui lui est conféré, la personne concernée devra être en mesure d'exiger de plus amples informations sur la décision prise ainsi que sur les modalités et les conséquences de celle-ci. Le projet de révision prévoit également des mesures relatives au profilage, lequel se fonde, lui aussi, souvent sur des algorithmes. Enfin, les responsables seront tenus de procéder à une analyse d'impact relative à la protection des données dans les cas où le traitement des données serait susceptible de porter atteinte à la personnalité ou aux droits fondamentaux de la personne concernée. L'opportunité de mesures visant la protection de la personne concernée sera également examinée dans le cadre de la révision.</p><p>Les mesures énumérées montrent que les problèmes que soulèvent les algorithmes en lien avec les droits constitutionnels ont été reconnus et qu'ils sont déjà pris en considération dans les analyses en cours. Le Conseil fédéral considère que le fait de poursuivre et de renforcer ces analyses constitue la manière la plus efficace de s'assurer que les algorithmes seront utilisés dans le respect des droits fondamentaux.</p>"
    },
    {
      "type": {
        "id": 5,
        "name": "Texte déposé"
      },
      "value": "<p>Le Conseil fédéral analyse l'impact sur les droits constitutionnels de l'utilisation d'algorithmes par les collectivités publiques et par les privés. Il présentera le cas échéant les mesures afin de rendre l'utilisation d'algorithmes transparente, responsable et respectueuse des droits fondamentaux.</p>"
    },
    {
      "type": {
        "id": 1,
        "name": "Titre de l'objet"
      },
      "value": "Pour des algorithmes respectueux des droits fondamentaux"
    }
  ],
  "title": "Pour des algorithmes respectueux des droits fondamentaux"
}