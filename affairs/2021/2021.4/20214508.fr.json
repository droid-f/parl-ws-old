{
  "id": 20214508,
  "updated": "2021-12-23T15:15:24Z",
  "additionalIndexing": "34;28;04",
  "affairType": {
    "abbreviation": "Mo.",
    "id": 5,
    "name": "Motion"
  },
  "author": {
    "councillor": {
      "code": 3180,
      "gender": "f",
      "id": 4288,
      "name": "Schlatter Marionna",
      "officialDenomination": "Schlatter"
    },
    "faction": {
      "abbreviation": "Groupe G",
      "id": 6,
      "name": "Groupe des VERT-E-S"
    },
    "type": "author"
  },
  "deposit": {
    "council": {
      "abbreviation": "CN",
      "id": 1,
      "name": "Conseil national",
      "type": "N"
    },
    "date": "2021-12-16T00:00:00Z",
    "legislativePeriod": 51,
    "session": "5112"
  },
  "descriptors": [

  ],
  "drafts": [
    {
      "consultation": {
        "resolutions": [

        ]
      },
      "federalCouncilProposal": {
        "code": "-",
        "date": "2022-02-16T00:00:00Z",
        "text": "Le Conseil fédéral propose de rejeter la motion."
      },
      "index": 0,
      "links": [

      ],
      "preConsultations": [

      ],
      "references": [

      ],
      "relatedDepartments": [
        {
          "abbreviation": "DFI",
          "id": 4,
          "name": "Département de l'intérieur",
          "leading": true
        }
      ],
      "states": [
        {
          "date": "/Date(1639609200000+0100)/",
          "id": 24,
          "name": "Non encore traité au conseil"
        }
      ],
      "texts": [

      ]
    }
  ],
  "language": "fr",
  "priorityCouncils": [
    {
      "abbreviation": "CN",
      "id": 1,
      "name": "Conseil national",
      "type": "N",
      "priority": 1
    }
  ],
  "relatedAffairs": [

  ],
  "roles": [
    {
      "councillor": {
        "code": 3137,
        "gender": "m",
        "id": 4245,
        "name": "Andrey Gerhard",
        "officialDenomination": "Andrey"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3164,
        "gender": "f",
        "id": 4272,
        "name": "Klopfenstein Broggini Delphine",
        "officialDenomination": "Klopfenstein Broggini"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3171,
        "gender": "m",
        "id": 4279,
        "name": "Pointet François",
        "officialDenomination": "Pointet"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3173,
        "gender": "m",
        "id": 4281,
        "name": "Pult Jon",
        "officialDenomination": "Pult"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2680,
        "gender": "f",
        "id": 3877,
        "name": "Fiala Doris",
        "officialDenomination": "Fiala"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2652,
        "gender": "f",
        "id": 1295,
        "name": "Graf-Litscher Edith",
        "officialDenomination": "Graf-Litscher"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3003,
        "gender": "m",
        "id": 4093,
        "name": "Glättli Balthasar",
        "officialDenomination": "Glättli"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3084,
        "gender": "f",
        "id": 4197,
        "name": "Marti Min Li",
        "officialDenomination": "Marti Min Li"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3122,
        "gender": "m",
        "id": 4221,
        "name": "Töngi Michael",
        "officialDenomination": "Töngi"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3208,
        "gender": "m",
        "id": 4312,
        "name": "Storni Bruno",
        "officialDenomination": "Storni"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3180,
        "gender": "f",
        "id": 4288,
        "name": "Schlatter Marionna",
        "officialDenomination": "Schlatter"
      },
      "faction": {
        "abbreviation": "Groupe G",
        "id": 6,
        "name": "Groupe des VERT-E-S"
      },
      "type": "author"
    }
  ],
  "shortId": "21.4508",
  "state": {
    "id": 24,
    "name": "Non encore traité au conseil",
    "doneKey": "0",
    "newKey": 0
  },
  "texts": [
    {
      "type": {
        "id": 6,
        "name": "Développement"
      },
      "value": "<p>Les systèmes de prise de décision fondés sur des algorithmes sont des instruments importants pour l'efficacité des procédures administratives, mais ils comportent des risques auxquels il faut faire face activement. La numérisation croissante de l'administration et le volume de données de plus en plus important entraîneront une utilisation accrue de ces systèmes. Il est donc indispensable de réfléchir dès à présent à la manière de les utiliser. Dans un premier temps, il faut être transparent sur le nombre de systèmes de ce type utilisés dans l'administration et sur leurs domaines d'utilisation. Cela permet non seulement à toutes les parties concernées et intéressées, y compris de la société civile, d'accéder à l'information mais cela facilite aussi en particulier la recherche d'intérêt public sur l'utilisation de ces systèmes. Il s'agit d'un élément essentiel pour un débat de société éclairé sur cette utilisation, ses conséquences et les conditions requises.</p><p>Dans le rapport \" Avenir du traitement et de la sécurité des données \", le Conseil fédéral dit qu'il faut notamment être transparent sur les algorithmes (voir mesure 50). Cette transparence n'est actuellement pas donnée. Pour savoir où la Confédération utilise des algorithmes le cas échéant, il faut soit qu'elle le communique activement soit que quelqu'un lui pose la question.</p><p>Pour que l'action de l'administration soit facilement accessible au public, compréhensible et vérifiable, il faut que les choses changent : la création d'un registre public peut ici contribuer à la transparence.</p><p>Le document de position rédigé par AlgorithmWatch Suisse en collaboration avec un consortium interdisciplinaire d'universitaires et soutenu par le DSI Strategy Lab (Université de Zurich) sur la réglementation des systèmes d'IA en Suisse exprime la même exigence.</p>"
    },
    {
      "type": {
        "id": 14,
        "name": "Réponse CF / Bureau"
      },
      "value": "<p>Le 25 août 2021, le Conseil fédéral a décidé de créer un réseau de compétences en intelligence artificielle (CNAI) qui devra être opérationnel au printemps 2022.</p><p>Un des mandats attribués au CNAI est la création, la mise en service et la mise à disposition dans le domaine public d'une base de données structurée présentant un aperçu de l'ensemble des projets en cours et des applications, référencés au sein du portefeuille informatique de la Confédération, ayant recours à l'intelligence artificielle (IA) ou en lien avec cette dernière, donc aussi aux systèmes décisionnels automatisés. Elle fournit des informations centrales telles que le nom du projet, le domaine thématique, l'institution concernée et les interlocuteurs, mais aussi des aspects importants en matière d'IA, tels que le type de données utilisées ainsi que les composants de l'apprentissage automatique. D'autres informations (par ex : le fabricant du système, l'analyse de l'impact sur la protection des données qui fait partie de la méthode de gestion de projet Hermes, etc.) pourront être demandées directement aux interlocuteurs mentionnés dans la base de données. Les projets et applications militaires classifiés, ainsi que ceux liés aux activités de renseignement sont explicitement exclus et ne figurent pas dans cette base de données. Une version minimale de cette base de données (liste publique) est d'ailleurs disponible depuis le 1er janvier 2022 sur le site Internet du CNAI (www.cnai.swiss).</p><p>En outre, plusieurs dispositions de la nouvelle loi fédérale sur la protection des données adoptée le 25 septembre 2020, améliorent la transparence. Si une décision individuelle automatisée émane d'un organe fédéral, elle doit être en principe qualifiée comme telle (art. 21, al. 4) ; l'existence d'une décision individuelle automatisée ainsi que la logique sur laquelle se base la décision doivent désormais aussi être communiquées à la personne qui exerce son droit d'accès (art. 25, al. 2, let. f). Enfin, une base légale formelle est exigée lorsque le mode du traitement (qui inclut aussi le recours à des algorithmes) est susceptible de porter gravement atteinte aux droits fondamentaux (art. 34, al. 2, let. c).</p><p>Le Conseil fédéral propose donc de rejeter la motion, son objectif étant déjà atteint.</p>"
    },
    {
      "type": {
        "id": 5,
        "name": "Texte déposé"
      },
      "value": "<p>Le Conseil fédéral est chargé de créer un registre public de tous les systèmes de prise de décision automatisée fondés sur des algorithmes utilisés dans l'administration fédérale. Le registre rendra publiques des informations sur l'utilisation prévue du système, sur son fonctionnement, sur son développeur et, si disponibles, sur les résultats d'une analyse d'impact.</p>"
    },
    {
      "type": {
        "id": 1,
        "name": "Titre de l'objet"
      },
      "value": "Créer un registre public des algorithmes utilisés par l'administration"
    }
  ],
  "title": "Créer un registre public des algorithmes utilisés par l'administration"
}