{
  "id": 20214406,
  "updated": "2021-12-10T09:27:13Z",
  "additionalIndexing": "34;1236;36;2841",
  "affairType": {
    "abbreviation": "Po.",
    "id": 6,
    "name": "Postulato"
  },
  "author": {
    "councillor": {
      "code": 3084,
      "gender": "f",
      "id": 4197,
      "name": "Marti Min Li",
      "officialDenomination": "Marti Min Li"
    },
    "faction": {
      "abbreviation": "Gruppo S",
      "id": 2,
      "name": "Gruppo socialista"
    },
    "type": "author"
  },
  "deposit": {
    "council": {
      "abbreviation": "CN",
      "id": 1,
      "name": "Consiglio nazionale",
      "type": "N"
    },
    "date": "2021-12-09T00:00:00Z",
    "legislativePeriod": 51,
    "session": "5112"
  },
  "descriptors": [

  ],
  "drafts": [
    {
      "consultation": {
        "resolutions": [

        ]
      },
      "federalCouncilProposal": {
        "code": "-",
        "date": "2022-02-16T00:00:00Z",
        "text": "Il Consiglio federale propone di respingere il postulato."
      },
      "index": 0,
      "links": [

      ],
      "preConsultations": [

      ],
      "references": [

      ],
      "relatedDepartments": [
        {
          "abbreviation": "DFI",
          "id": 4,
          "name": "Dipartimento dell'interno",
          "leading": true
        }
      ],
      "states": [
        {
          "date": "/Date(1639004400000+0100)/",
          "id": 24,
          "name": "Non ancora trattato dalla Camera"
        }
      ],
      "texts": [

      ]
    }
  ],
  "language": "it",
  "priorityCouncils": [
    {
      "abbreviation": "CN",
      "id": 1,
      "name": "Consiglio nazionale",
      "type": "N",
      "priority": 1
    }
  ],
  "relatedAffairs": [

  ],
  "roles": [
    {
      "councillor": {
        "code": 3137,
        "gender": "m",
        "id": 4245,
        "name": "Andrey Gerhard",
        "officialDenomination": "Andrey"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3162,
        "gender": "m",
        "id": 4270,
        "name": "Hurni Baptiste",
        "officialDenomination": "Hurni"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3165,
        "gender": "f",
        "id": 4273,
        "name": "Locher Benguerel Sandra",
        "officialDenomination": "Locher Benguerel"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3166,
        "gender": "m",
        "id": 4274,
        "name": "Mäder Jörg",
        "officialDenomination": "Mäder"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3192,
        "gender": "f",
        "id": 4300,
        "name": "Widmer Céline",
        "officialDenomination": "Widmer Céline"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3036,
        "gender": "f",
        "id": 4134,
        "name": "Munz Martina",
        "officialDenomination": "Munz"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 2726,
        "gender": "f",
        "id": 3923,
        "name": "Marra Ada",
        "officialDenomination": "Marra"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3094,
        "gender": "f",
        "id": 4199,
        "name": "Seiler Graf Priska",
        "officialDenomination": "Seiler Graf"
      },
      "type": "cosign"
    },
    {
      "councillor": {
        "code": 3084,
        "gender": "f",
        "id": 4197,
        "name": "Marti Min Li",
        "officialDenomination": "Marti Min Li"
      },
      "faction": {
        "abbreviation": "Gruppo S",
        "id": 2,
        "name": "Gruppo socialista"
      },
      "type": "author"
    }
  ],
  "shortId": "21.4406",
  "state": {
    "id": 24,
    "name": "Non ancora trattato dalla Camera",
    "doneKey": "0",
    "newKey": 0
  },
  "texts": [
    {
      "type": {
        "id": 6,
        "name": "Motivazione"
      },
      "value": "<p>I sistemi di ADM o l'intelligenza artificiale sono impiegati in un numero crescente di ambiti, sia nel settore privato che in quello pubblico. Questa tecnologia comporta però anche dei rischi. Alcuni esempi mostrano che le decisioni possono essere discriminatorie (ad es. Amazon e il sistema di selezione del personale) oppure sbagliate o pericolose (ad es. gli strumenti diagnostici di IBM Watson per l'oncologia) a causa di distorsioni nei modelli o nei dati sperimentali oppure a causa di circostanze sociali o economiche. Le decisioni automatizzate possono inoltre comportare gravi limitazioni dei diritti fondamentali o avere un effetto deterrente sul loro esercizio, ad esempio nel settore delle attività di prevenzione della polizia. Persino i sistemi che la Commissione europea ha giudicato a basso rischio possono essere altamente problematici, come i casi di cosiddetto \"deep fake\".</p><p>Sia nel settore privato che in quello pubblico, per l'opinione pubblica e i diretti interessati spesso non è possibile riconoscere dove vengano impiegati i sistemi di ADM né rendersene conto quando la cosa li riguarda. D'altro canto, spesso non è chiaro a quale scopo e da chi venga usato un sistema di questo tipo e come funzioni. Il rapporto dovrà porre rimedio a questa situazione. Inoltre, dovrà illustrare come si possa migliorare la trasparenza sia per i diretti interessati che per l'opinione pubblica in generale (ad es. attraverso l'obbligo di informare gli interessati o mediante l'istituzione di un registro pubblico con informazioni di base sui sistemi di ADM utilizzati nel settore pubblico). La necessità di intervento è stata segnalata anche nel parere su un quadro giuridico per l'intelligenza artificiale della Digital Society Initiative dell'Università di Zurigo (\"Ein Rechtsrahmen für künstliche Intelligenz\").</p>"
    },
    {
      "type": {
        "id": 14,
        "name": "Risposta del CF / Ufficio"
      },
      "value": "<p>L'intelligenza artificiale (IA) solleva molte domande per le piazze economiche innovative e rivolte verso il futuro, che ritengono di agire secondo il principio dello Stato di diritto. Il Consiglio federale si era già occupato del tema nel 2019 alla luce di un esame della situazione, prendendo atto del rapporto del gruppo di lavoro interdipartimentale \"Intelligenza artificiale\". Nel 2020 ha adottato delle linee guida concernenti l'utilizzo dell'IA e ha incaricato il Dipartimento federale dell'ambiente, dei trasporti, dell'energia e delle comunicazioni (DATEC) di valutare periodicamente l'applicazione e lo sviluppo di queste ultime in collaborazione con gli uffici interessati. Nel 2021 il Consiglio federale ha incaricato il Dipartimento federale dell'interno (DFI) di mettere a punto una rete di competenze per l'IA (CNAI) nella primavera del 2022. L'analisi delle sfide e delle opportunità coincide quindi in ampia misura con il parere della Digital Society Initiative dell'Università di Zurigo, menzionato nel postulato.</p><p>In ordine alla necessità di legiferare, sulla base del rapporto succitato il Consiglio federale è giunto alla conclusione che al momento non è necessario alcun nuovo quadro giuridico generale. L'IA può senz'altro far sorgere domande in vari settori (p. es. in materia di diagnostica medica, agricoltura, tribunali), ma queste sono già coperte dal diritto in vigore e vi trovano generalmente una buona risposta. In caso contrario, occorre trovare soluzioni ad hoc. In alcuni settori, ciò può comportare la revisione di una legge o di un'ordinanza. A tal proposito, la nuova legge federale sulla protezione dei dati adottata nel 2020 prevede già varie disposizioni che migliorano la trasparenza in questo ambito, sia per il settore privato che per quello pubblico. L'articolo 21 introduce infatti l'obbligo di informare sulle decisioni individuali automatizzate e il diritto della persona interessata di esigere che la decisione sia riesaminata da una persona fisica; alla persona che esercita il proprio diritto di accesso ora devono essere comunicate anche l'esistenza di una decisione individuale automatizzata e la logica su cui si fonda la decisione (art. 25 cpv. 2 lett. f). Per il trattamento di dati degli organi federali è richiesta una base legale formale quando il tipo di trattamento (che include il ricorso ad algoritmi) può comportare una grave ingerenza nei diritti fondamentali della persona interessata (art. 34 cpv. 2 lett. c). Infine, il Consiglio federale ha incaricato il Dipartimento federale delle finanze (DFF) di fornire entro la fine del 2022 un'analisi del quadro giuridico per l'applicazione dell'IA nel settore finanziario. Grazie alla sua banca dati strutturata accessibile al pubblico, la CNAI accrescerà la fiducia e la trasparenza in queste tecnologie. Inoltre, la Svizzera partecipa attivamente ai lavori dell'OCSE, del Consiglio d'Europa, dell'UNESCO e dell'Unione internazionale delle telecomunicazioni (UIT) nell'ottica di elaborare un quadro normativo internazionale sull'IA. La Confederazione segue quindi da vicino le discussioni sul progetto di regolamentazione dell'IA nell'UE e ne analizza le possibili conseguenze per la Svizzera. In tale contesto, nel suo rapporto del 2021 al Consiglio federale, il DATEC ha mostrato come gli intermediari e le piattaforme di comunicazione basate sull'IA influiscano sulla comunicazione pubblica in Svizzera e sulla formazione dell'opinione pubblica svizzera; il Consiglio federale ha quindi incaricato il DATEC di indicargli entro la fine del 2022 se e come regolamentare tali piattaforme. Il Consiglio federale ha inoltre incaricato il Dipartimento federale degli affari esteri (DFAE) di stilare un rapporto sul quadro normativo internazionale concernente l'IA in fase di elaborazione e sulle possibili modalità di partecipazione della Svizzera a tali lavori. In ordine alla necessità o meno di creare una commissione nazionale di etica, il Consiglio federale ha già risposto negativamente nel maggio del 2021 nel quadro dell'interpellanza Schlatter 21.3239. Si ricorda che la piattaforma tripartita, diretta dal DATEC, funge da organo di scambio aperto a tutte le parti che si interessano di questioni relative all'IA e dispone di un comitato amministrativo incaricato del coordinamento delle posizioni svizzere negli organismi e nei processi internazionali. Infine, nel quadro della strategia \"Svizzera digitale\" e della strategia di politica estera digitale 2021-2024, il Consiglio federale presenterà di nuovo un rapporto in merito. Considerati i lavori inerenti al quadro normativo per l'IA già in corso a livello nazionale e internazionale, per il momento un mandato parlamentare non sembra essere necessario.</p>"
    },
    {
      "type": {
        "id": 5,
        "name": "Testo depositato"
      },
      "value": "<p>Il Consiglio federale è incaricato di presentare un rapporto che illustri se e dove vi sia esigenza di regolamentazione nell'ambito dei sistemi di decisione automatizzata (automated decision making, ADM) o dell'intelligenza artificiale. L'analisi dovrà focalizzarsi sulla garanzia della trasparenza, il rispetto delle direttive etiche e la prevenzione di discriminazioni o manipolazioni. Un altro aspetto che richiede un chiarimento giuridico è l'attribuzione di responsabilità, cioè la questione di chi debba rispondere delle previsioni, raccomandazioni o decisioni formulate dai sistemi di ADM. Occorre chiarire se le basi e gli strumenti legali siano sufficienti per contrastare questi rischi. In questo contesto, dovrà essere esaminata anche la possibilità di istituire una commissione etica nazionale. Il rapporto dovrà inoltre illustrare in quali ambiti del settore pubblico questi sistemi sono già in uso (ad es. nel perseguimento penale) ed eventualmente dove mancano basi legali.</p>"
    },
    {
      "type": {
        "id": 1,
        "name": "Titolo dell'oggetto"
      },
      "value": "Rapporto sulla regolamentazione dei sistemi decisionali automatizzati"
    }
  ],
  "title": "Rapporto sulla regolamentazione dei sistemi decisionali automatizzati"
}